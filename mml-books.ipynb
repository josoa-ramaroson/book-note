{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0d135a-f09d-49ee-952f-fa24f2a44570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.text_cell_render {\n",
       "    line-height: 1.5 !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "div.text_cell_render {\n",
    "    line-height: 1.5 !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf8022-8984-4039-8f44-2b47380c29d2",
   "metadata": {},
   "source": [
    "# Chapter 5 : Vector Calculus\n",
    "(see copy book for the missing sections)\n",
    "## 5.6 Backpropagation and Automatic Differentiation\n",
    "(see notebook for missing subsections)\n",
    "### 5.6.2 Automatic Differentiation\n",
    "- Automatic differentiation applies a series of elementary arithmetic operations, e.g., addition and multiplication and elementary functions, e.g., sin, cos, exp, log.\n",
    "- by applying the chain rule to these operations, the gradient of quite complicated functions can be computed automatically.\n",
    "- from dataflow between x and y, and by applying intermediate variables a,b, we can obtain this:\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\frac{dy}{dx} = \\frac{dy}{db} \\cdot \\frac{db}{da} \\cdot \\frac{da}{dx} \\tag{5.119}\n",
    "\\end{align}\n",
    " $$\n",
    "- Intuitively, the forward and reverse mode differ in the order of multiplication. Due to the associativity of matrix multiplication, we can choose between :\n",
    "$$ \n",
    "\\begin{align}\n",
    "  \\frac{dy}{dx} = \\left( \\frac{dy}{db} \\cdot \\frac{db}{da} \\right) \\cdot \\frac{da}{dx} \\tag{5.120} \\\\\n",
    "  \\frac{dy}{dx} = \\frac{dy}{db} \\cdot \\left( \\frac{db}{da} \\cdot \\frac{da}{dx} \\right) \\tag{5.121}\n",
    "\\end{align}\n",
    "$$ \n",
    "- reverse mode (5.120) :  gradients are propagated backward through the graph, i.e., reverse to the data flow. (backpropagation) the reverse mode is computationally significantly cheaper than the forward mode in Neural Networks.\n",
    "- forward mode (5.121): where the gradients flow with the data from left to right through the graph.\n",
    "- exemple : see P162 which explains the concept of intermediate variables Computation graph\n",
    "with inputs x, function values f ,  and intermediate variables a, b, c, d, e.The set of equations that include intermediate variables can be thought of as a computation graph. In this examples, it shows how we can obtain $ \\frac{\\partial f}{\\partial x} $ . we observe that the computation required for calculating the derivative is of similar complexity as the computation of the function itself.\n",
    "- **Formalization** : Let $x_1 , . . . , x_d$ be the input variables to the function, $x_d+1 , . . . , x_D−1$ be the intermediate variables, and $x_D$ the output variable. Then the computation graph can be expressed as follows:\n",
    "    $$  \\text{For  }  i = d+1,...,D:   x_i = g_i\\left(x_{\\text{Pa}(x_i)}\\right) $$\n",
    "  Where the $ g_i\\left(\\cdot\\right) $ are elementary functions and $  x_{\\text{Pa}(x_i)} $ are the parent nodes of the variable xi in the graph.\n",
    "  For other variables $ x_i $, we apply the chain rule :\n",
    "$$\n",
    "   \\frac{\\partial f} {\\partial x_i}\n",
    "    = \\sum_{x_j : x_i \\in Pa(x_j)} \n",
    "        \\frac{\\partial f}{\\partial x_j} \\,\n",
    "        \\frac{\\partial x_j}{\\partial x_i}\n",
    "    = \\sum_{x_j : x_i \\in Pa(x_j)}\n",
    "        \\frac{\\partial f}{\\partial g_j} \\,\n",
    "        \\frac{\\partial g_j}{\\partial x}\n",
    "        \\tag{5.145}\n",
    "  $$\n",
    "Where $ \\text{Pa} \\left( x_j \\right) $ is the set of parent nodes of $x_j$ in the computation graph.  (5.145) is the backpropagation of the gradient through the computation graph.\n",
    "- For neural network training, we backpropagate the error of the prediction with respect to the label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc2a54-96f8-4001-aec4-6e852c923f04",
   "metadata": {},
   "source": [
    "## 5.7 Higher-Order Derivatives\n",
    "- Sometimes, we are interested in derivatives of higher order, e.g., when we want to use Newton’s Method for optimization, which requires second-order derivatives (Nocedal and Wright, 2006).\n",
    "- Consider a function $f : \\mathbb{R}^2 \\to \\mathbb{R}$ of two variables $x, y $. We use the following notation for higher-order partial derivatives (and for gradients):\n",
    "  - $\\frac{\\partial^2 f}{\\partial^2 x} $ is the second partial derivative of f with respect to x.\n",
    "  - $\\frac{\\partial^n f}{\\partial^n x} $ is the nth partial derivative of f with respect to x.\n",
    "  - $\\frac{\\partial^2 f}{\\partial y \\cdot \\partial x} = \\frac{\\partial}{\\partial y} \\left( \\frac{\\partial f}{\\partial x} \\right) $  is the partial derivative obtained by first partial differentiating with respect to x and then with respect to y.\n",
    "  - $\\frac{\\partial^2 f}{\\partial x \\cdot \\partial y}$ s the partial derivative obtained by first partial differentiating by y and then x.\n",
    "- *Hessian* : the collection of all second-order partial derivatives\n",
    "- If f (x, y) is a twice (continuously) differentiable function, then  $\\frac{\\partial^2 f}{\\partial y \\cdot \\partial x} = \\frac{\\partial^2 f}{\\partial x \\cdot \\partial y}$; i.e, the order of differentiation does not matter.\n",
    "- We obtain then the *Hessian matrix* :\n",
    "$$\n",
    "      \\textbf{H} =\n",
    "\\begin{bmatrix}\n",
    "   \\frac{\\partial^2 f}{\\partial x^2} &  \\frac{\\partial^2 f}{\\partial x  \\partial y} \\\\\n",
    "  \\frac{\\partial^2 f}{\\partial x  \\partial y} & \\frac{\\partial^2 f}{ \\partial y^2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- This matrix is symmetric. noted $ \\nabla_{x,y}^2 f(x,y)$, which is generaly an n x n matrix for $x \\in \\mathbb{R}^n$\n",
    "- The Hessian measures\n",
    "the curvature of the function locally around (x, y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467d019-d3b3-4389-843a-d58dd825ab8e",
   "metadata": {},
   "source": [
    "## 5.8 Linearization and Multivariate Taylor Serie\n",
    "- linear approximation of f around $x_0$:\n",
    "  $$\n",
    "  f(x) \\approx f(x_0) + (\\nabla_x f) (x_0) ( x - x_0) \\tag{5.148}\n",
    "  $$\n",
    "   $(\\nabla_x f) (x_0) $ : the gradient of f with respect to x, evaluated at $x_0$ (an input)\n",
    "- The original function is approximated by a straight line. This approximation is locally accurate, but the farther we move away from $x_0$ the worse the approximation gets.\n",
    "- a special case of a multivariate Taylor series expansion of f at $x_0$, where we consider only the first two terms\n",
    "- **Definition of Multivariate Taylor Series** : \n",
    "   - Consider the function : $$\n",
    "  f : \\mathbb{R}^D \\to \\mathbb(R), \n",
    "  \\quad x \\mapsto f(x), \\quad x \\in \\mathbb{R}^D\n",
    "  $$ => is smoot at $x_0$\n",
    "   - When we define the difference vector $\\delta := x - x_0$, the *Multivariate Tailor series* of $f$ at ($x_0$) is defined as\n",
    "     $$\n",
    "     f(x) = \\sum_{k=0}^{\\infty} \\frac{D_{x}^k f(x_0) } {k!} \\, \\delta^k\n",
    "     $$\n",
    "     Where $D_{x}^k f(x_0)$ is the k -th (total) derivative of f with respect to x, evaluated at $x_0$ .\n",
    "- **Taylor Polynomial** :  The Taylor polynomial of degree n of f at x0 contains the first n + 1 components of the series in (5.151) and is defined as :\n",
    "  $$\n",
    "  T_n(x) = \\sum_{k=0}^n \\frac{D_{x}^k f(x_0)} {k!}\\, \\delta^k\n",
    "  $$\n",
    "  $\\delta^k$ is not defined for vectors $x \\in \\mathbb(R)^D, D > 1 \\text{ and } k>1$\n",
    "  Both $D_{x}^k f(x_0)$ and $\\delta^k$ are $k$-th order tensors, i.e, $k$-dimensional arrays.\n",
    "  The $k$th-order tensor $\\delta^k \\in \\mathbb{R}^{D x D x ...xD}$ is obtained as a $k$-fold outer product, denoted \\otimes, of the vector $\\delta \\in \\mathbb{R}^D$. For example $$\n",
    "\\delta^2 := \\delta \\otimes \\delta = \\delta \\, \\delta^T, \\quad\n",
    "\\delta^2 \\!\\left[ i, j \\right] = \\delta_i \\, \\delta_j\n",
    "- Exemple: Taylor Series Expansion of a Function with Two Vari-\n",
    "ables (P 167)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb227e9-d8b0-46e6-a439-7343c48ba0f3",
   "metadata": {},
   "source": [
    "## 5.9 Further Reading (p170)\n",
    "\n",
    "- **Matrix differentials**: Matrix Differential Calculus with Applications in Statistics and Econometrics, Magnus, Jan R., and Neudecker, Heinz. 2007.\n",
    "- **Automatic differentiation**: Elliott, Conal. 2009. Beautiful Differentiation. In: International Conference on Functional Programming. Griewank, Andreas, and Walther, Andrea. 2008. Evaluating Derivatives, Principles and Techniques of Algorithmic Differentiation. SIAM.\n",
    "- **Extended Kalman filter**: Maybeck, Peter S. 1979. Stochastic Models, Estimation, and Control. Academic Press.\n",
    "- **Other deterministic ways** to approximate the integral. unscented transform : Julier, Simon J., and Uhlmann, Jeffrey K. 1997. A New Extension of the Kalman Filter to  nonlinear Systems. In: Proceedings of AeroSense Symposium on Aerospace/Defense Sensing, Simulation and Controls.\n",
    "or the **Laplace approximation** of Murphy, Kevin P. 2012. Machine Learning: A Probabilistic Perspective. MIT Press."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f8066-1e21-495f-a9c3-3da59b9a56ac",
   "metadata": {},
   "source": [
    "# Chapter 6: Probability and Distributions\n",
    "- study of uncertainty\n",
    "- use this probability to measure the chance of something occurring in an experiment\n",
    "- *random variable* : Quantifying uncertainty. a function that maps outcomes of random experiments to a set of properties that we are interested in.\n",
    "- *probability distribution* : a function that measures the probability that a particular outcome (or set of outcomes) will occur. used in probabilistic modeling (Section 8.4), graphical models (Section 8.5), and model selection (Section 8.6).\n",
    "- *probability space* :the sample space, the events, and the probability of an event "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e975cd-f374-4f94-bf1a-bba86cbc23a8",
   "metadata": {},
   "source": [
    "## 6.1 Construction of a Probability Space (p172)\n",
    "The theory of probability aims at defining a mathematical structure to describe random outcomes of experiments. (see Jaynes, Edwin T. 2003. Probability Theory: The Logic of Science. Cambridge University Press.)\n",
    "### 6.1.1 Philosophical Issues\n",
    "- For plausible reasoning it is necessary to extend the discrete true and false values of truth\n",
    "to continuous plausibilities\n",
    "- probability theory can be considered a generalization of Boolean logic.\n",
    "- In ML, it is used to formalize the design of automated reasoning systems. (Pearl, Judea. 1988. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann.)\n",
    "- plausibility by E. T. Jaynes (1922 - 1998) :\n",
    "      1. The degrees of plausibility are represented by real numbers.\n",
    "      2. These numbers must be based on the rules of common sense.\n",
    "      3. . The resulting reasoning must be consistent, with the three following meanings of the word “consistent”: consistency or non-contradiction, honesty, reproducibility.\n",
    "- **Cox–Jaynes theorem** (p174) : universal mathematical rules that apply to plausibility p\n",
    "- **Remark** : two interpretation of the probability in ML: the Bayesian (*“subjective probability” or “degree of belief”*) and frequentist interpretations (see Bishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer.)\n",
    "- in ML, consider wether we are trying to model something categorical (a discrete random variable) or something continuous (a continuous random variable).\n",
    "\n",
    "### 6.1.2 Probability and Random Variables\n",
    "- three idea to not to be confused\n",
    "  - **probability space**: allows us to quantify the idea of a probability\n",
    "  - **random variables** :transfers the probability to a more convenient (often numerical) space.\n",
    "  - **distribution or law associated with a random variable**\n",
    "- from *Grinstead, Charles M., and Snell, J. Laurie. 1997. Introduction to Probability. American Mathematical Society.*, modern probability is based on:\n",
    "    - *The sample space $\\Omega$* (\"state space\" “sample description space”, “possibility space,” and “event space”) : he set of all possible outcomes of the experiment, usually denoted by $\\Omega$.\n",
    "    - *The event space $\\mathcal{A}$* (collection of subsets of $\\Omega$ ) :  the space of potential results of the experiment. A subset $A$ of the sample space $\\Omega$ is in the event space $\\mathcal{A}$ if at the end of the experiment we can observe whether a particular outcome $\\omega \\in \\Omega$ is in $A$.\n",
    "    - *The probabilty $P$* ( $P(A)$ ) : With each event $A \\in \\mathcal{A}$, we associate a number $P(A)$ that measures the probability or degree of belief that the event will occur. in $\\left[0, 1\\right]$ and $P(\\Omega) = 1$ \n",
    "\n",
    "- The *probability space* $(\\Omega, \\mathcal{A}, P)$ models a real-world process or phenomenon. (referred to as an experiment) with random outcomes. In ML, instead we refer to it as *probabilities on quantities of interest* denoted by $\\mathcal{T}$.\n",
    "- $\\mathcal{T}$ : *Taget space*, **element of $\\mathcal{T}$** :states\n",
    "- ***Random Variable*** : It is a function $X: \\Omega \\to \\mathcal{T}$ that takes an element of $\\Omega$ (an outcome) and returns a particular quantity of interest $x$, a value in $\\mathcal{T}$. For any subset $S \\subseteq \\mathcal{T}$ , we associate $P_{X}(S) \\in \\left[0, 1\\right]$ (the probability) to a particular event occurring corresponding to the random variable $X$ .\n",
    "- Exemple (P176) : Consider a statistical experiment where we model a funfair game consisting of drawing two coins from a bag (with replacement) . (see the rest on the book)\n",
    "- *the probability of the output of X $\\neq$ the probability of the samples in $\\Omega$*\n",
    "- $X^{-1}(S)$: Pre-image of $S$  by $X$: The set of elements of $\\Omega$ that map to $S$ under $X$: $\\{\\omega \\subset \\Omega: X(\\omega) \\subset S\\}$\n",
    "- the random variable $X$ is to associate it with the probability of the pre-image of $S$:\n",
    "  $$\n",
    "    P_{X}(S) = P(X \\subset S) = P(X^{-1}(S)) = P (\\{\\omega \\subset \\Omega: X(\\omega) \\subset S\\}) \\tag{6.8}\n",
    "  $$\n",
    "- *Law Distribution* of random variable $X$: the function $P_X$ or equivalently $P \\circ X^{−1}$\n",
    "- **Remark** : The target space, that is, the range $\\mathcal{T}$ of the random variable $X$ , is used to indicate the kind of probability space, i.e., a $\\mathcal{T}$ random variable. When $\\mathcal{T}$ is finite or countably infinite, this is called a discrete random variable (Section 6.2.1). For continuous random variables (Section 6.2.2), we only consider $\\mathcal{T} = \\mathbb{R}$ or $\\mathcal{T} = \\mathbb{R}^D$.\n",
    "\n",
    "### 6.1.3 Statistics\n",
    "- Using probability, we can consider a model of some process, where the underlying uncertainty is captured by random variables, and we use the rules of probability to derive what happens.\n",
    "- In statistics, we observe that something has happened and try to figure out the underlying process that explains the observations.\n",
    "- Thus ML is very close to statistics but We can use the rules of probability to obtain a “best-fitting” model for some data.\n",
    "- in ML, we are intereste in generalization error (perforamance analysis). This analysis of future performance relies on probability and statistics (see *Concentration Inequalities: A Nonasymptotic Theory of Independence. Oxford University Press* or *Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press.*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfefe8-c4c3-424d-bd92-59b1e8653c68",
   "metadata": {},
   "source": [
    "## 6.2 Discrete and Continuous Probabilities\n",
    "- focus our attention on ways to describe the probability of an event\n",
    "- Depending on whether the target space is discrete or continuous, the natural way to refer to distributions is different\n",
    "- *probability mass function* for discrete target space $\\mathcal{T}$: $P(X = x)$  the probability that a random variable $X$ takes a particular value $x \\in \\mathcal{T}$.\n",
    "- *cumulative distribution function*  $P(X \\leq x)$: by convention to pecify the probability that a random variable $X$ is less than a particular value $x$. Generaly, we specify the probability that a random variable $X$ is in an interval, denoted by $P(a \\leq X \\leq b)$ for $a \\leq b$.\n",
    "- **Remark** :\n",
    "    - *univariate distribution* to refer to distributions of a single random variable.\n",
    "    - *multivariate distributions*: a vector of random variables\n",
    "### 6.2.1 Discrete Probabilities\n",
    "- Target space is discrete => The probabilty distribution of multiple random variables is same as filling out a (multidimensional) array of numbers.\n",
    "- *Joint probability*: The Cartesian product of the target spaces of each of the random variables.\n",
    "$$\n",
    "P(X = x_i, Y = y_j) = \\frac{n_{ij}}{N}\n",
    "$$\n",
    "Where $n_{ij}$ is the number of events with state $x_i$ and $y_j$ and $N$ the total\n",
    "number of events.\n",
    "\n",
    "or \n",
    "$$\n",
    "P(X = x_i, Y = y_j) = P(X = x_i \\cap Y = y_j)\n",
    "$$\n",
    "- For two random variables $X$ and $Y$ , the probability that $X = x$ and $Y = y$ is (lazily) written as $p(x, y)$ and is called the joint probability.\n",
    "- The *marginal probability* that $X$ takes the value $x$ irrespective of the value of random variable $Y$ is (lazily) written as $p(x)$. We write $X \\sim p(x)$ to denote that the random variable X is distributed according to $p(x)$.\n",
    "- *Conditional probabilty* : if we consider only $X=x$, the probabilty for $Y=y$ is written as $p(y|x)$.\n",
    "- Exemple : see p179\n",
    "- in ML, we use discrete probability distributions to model *categorical variables*.\n",
    "- Discrete distributions are also often used to construct probabilistic models that combine a finite number of continuous distributions\n",
    "### 6.2.2 Continuous Probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1378a9-40f4-4bde-b374-0ffe40bd5847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
